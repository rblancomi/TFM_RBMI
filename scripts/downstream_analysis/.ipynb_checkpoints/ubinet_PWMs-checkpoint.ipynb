{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42a1d73-e12d-4f61-92b0-3c4e0758f046",
   "metadata": {},
   "source": [
    "# UbiNet motifs. From Position Probability Matrices (PPMs) to Position Weight Matrices (PWMs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe1cf3-ed90-4efa-ba6f-ec41b5122304",
   "metadata": {},
   "source": [
    "This notebook contains the code to extract the Position Probability Matrices (PPMs) degron motifs from [Ubinet 2.0. database](https://awi.cuhk.edu.cn/~ubinet/index.php) and transforms them into Position Weight Matrices (PWMs). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd859416-1430-4e8c-800e-7a3a988dd9d5",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc791ab-a5fb-4b82-9e07-17253075fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm           \n",
    "from bs4 import BeautifulSoup      # html parsing library\n",
    "import re                          # regular expressions library\n",
    "import requests                    # allows sending http requests\n",
    "import logomaker                   # for probability matrix transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a854b-cf4e-4948-99ac-13dab6f02741",
   "metadata": {},
   "source": [
    "## Define variables and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98dd969-70af-4089-b76c-032350c26a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../../\"\n",
    "\n",
    "data = \"data/\"\n",
    "\n",
    "prob_m_path = os.path.join(base, data, \"ubinet/motif_matrices/PPM/\")                      \n",
    "weight_m_path = os.path.join(base, data, \"ubinet/motif_matrices/PWM/\")                 \n",
    "aa_bg_path = os.path.join(base, data, \"external/aminoacid_frequency.txt\")  \n",
    "html_ubinet_path = os.path.join(base, data, \"external/ubinet/browseE3_ubinet.php\")\n",
    "url_motifs_path = os.path.join(base, data, \"ubinet/motif_links_ubinet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55834373-0ec7-4b52-85ab-9f49c3b30a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "# aa background probabilities (sorted by aa)\n",
    "bg_matrix = pd.read_table(aa_bg_path).sort_values(by = \"Aminoacid\")\n",
    "\n",
    "aa_probs = bg_matrix[\"Frequency\"].to_numpy()            # array with aa background frequencies\n",
    "aa = bg_matrix[\"Aminoacid\"].to_numpy()                  # array with aa names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2451b-e56e-4502-be8f-cd621e0fa97f",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072a192a-3daa-4153-af14-f98487fd6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test OK!\n",
    "def retrieve_motif_links(html_path, links_path, regex, save = True):\n",
    "    \"\"\"\n",
    "    Retrieves motifs hyperlinks matching regexs from a HTML file and save these links in a \n",
    "    text file, printing the total number of links\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    html_path: str\n",
    "                Path to the folder where the HTML file is located\n",
    "    links_path: str\n",
    "                Path to the folder where the text file with all hyperlinks will be located\n",
    "    regex: str\n",
    "                Regular expression to match every motif containing link\n",
    "    save: boolean (default: True)\n",
    "                If True, the links text file is generated. If false, only prints the number\n",
    "                of retrieved links\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Read website HTML file and apply HTML parser to it\n",
    "    with open(html_path) as fp:\n",
    "        soup = BeautifulSoup(fp, \"html.parser\")\n",
    "    \n",
    "    if save:\n",
    "    # Retrieve all hyperlinks and save then in a txt file\n",
    "        counter = 0                 # (optional) Monitor number of retrieved motifs\n",
    "\n",
    "        with open(links_path, \"w\") as fp:\n",
    "            for link in soup.find_all(href = re.compile(regex)):\n",
    "                counter += 1      \n",
    "                # use get function to only retrieve links after 'href' tag\n",
    "                fp.write(link.get('href')[1:]+\"\\n\")        # Note: [1:] to avoid the dot at the beginning\n",
    "\n",
    "    else:\n",
    "        counter = 0\n",
    "        for link in soup.find_all(href = re.compile(regex)):\n",
    "                counter += 1\n",
    "    \n",
    "    print(f'{counter} retrieved links')\n",
    "        \n",
    "    return None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a05d2-57d0-42d6-82a9-e9b75faafe12",
   "metadata": {},
   "source": [
    "Note: `<a>` tag defines a hyperlink in HTML, which most important attribute is `href`, which indicates the link's destination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244374c9-e32d-4dba-b985-836209d77a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests OK!\n",
    "def retrieve_prob_matrices(links_path, prob_m_path, urlbase, regex, one_pm = True, save = True):\n",
    "    \"\"\"\n",
    "    Retrieves motifs probability matrices from a HTML request to the motifs hyperlinks \n",
    "    and saves each matrix in a separated tab-delimited file, whose name is the E3-ligase AC. \n",
    "    Also, prints the number of retrieved matrices\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    links_path: str\n",
    "                Path to the folder where the text file with all hyperlinks is located\n",
    "    prob_m_path: str\n",
    "                Path to the folder where the probability matrices files will be located\n",
    "    urlbase: str\n",
    "                Non-mutable part of the URL to access the website\n",
    "    regex: str\n",
    "                Regular expression to find the probability matrix in the HTML tree\n",
    "    one_pm: boolean (default:True)\n",
    "                If True, only the first probability matrix instance per HTML is retrived.\n",
    "                If False, every probability matrix instance is retrived\n",
    "    save: boolean (default: True)\n",
    "                If True, the probability matrices are saved independently in text files.\n",
    "                If False, only prints the number of retrived matrices\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Access each motif's url and find the first frequency matrix instance\n",
    "    if one_pm:\n",
    "        \n",
    "        counter = 0                 # (optional) Monitor number of E3-ligases\n",
    "\n",
    "        with open(links_path) as fp:\n",
    "            for url in tqdm(fp):\n",
    "                counter += 1\n",
    "                E3_id = url.split(\"/\")[3]   # E3-ligase AC position in the URL\n",
    "                r = (requests.get(urlbase+url.strip())).text\n",
    "                soup = BeautifulSoup(r, \"html.parser\")\n",
    "                matrix = ((soup.find(value = re.compile(regex))).get(\"value\")).split(\"=\")[-1][3:]\n",
    "\n",
    "                # Store each probability matrix independently\n",
    "                if save:\n",
    "                    with open(prob_m_path+E3_id+\".tsv\", \"w\") as fp:\n",
    "                        fp.write(matrix)\n",
    "                        \n",
    "    \n",
    "    \n",
    "    # Access each motif's url and find every frequency matrix instance\n",
    "    else:\n",
    "        \n",
    "        counter = 0                       # (optional) Monitor number of E3-ligases\n",
    "        \n",
    "        with open(links_path) as fp:\n",
    "            for url in tqdm(fp):\n",
    "                E3_id = url.split(\"/\")[3]   # E3-ligase AC position in the URL\n",
    "                r = (requests.get(urlbase+url.strip())).text\n",
    "                soup = BeautifulSoup(r, \"html.parser\")\n",
    "                matrices = soup.find_all(value = re.compile(regex))\n",
    "    \n",
    "                # First matrix\n",
    "                matrix_1 = str(matrices[0]).split(\"=\")[-1][3:].split('\"')[0]\n",
    "                counter += 1\n",
    "                if save:\n",
    "                    with open(prob_m_path+E3_id+\".tsv\", \"w\") as fp:\n",
    "                        fp.write(matrix)\n",
    "    \n",
    "                # Rest of matrices (checked there is always a second matrix, a replicate of the first if there are not two)\n",
    "                for i, matrix in enumerate(matrices[1:]):\n",
    "                    matrix_n = str(matrix).split(\"=\")[-1][3:].split('\"')[0]\n",
    "                    \n",
    "                        \n",
    "                    # An additional matrix exists\n",
    "                    if matrix_1 != matrix_n:\n",
    "                        counter += 1\n",
    "                        if save:\n",
    "                            with open(prob_m_path+E3_id+\"_\"+str(i+2)+\".tsv\", \"w\") as fp:\n",
    "                                fp.write(matrix)\n",
    "    \n",
    "    \n",
    "    print(f'{counter} retrieved probability matrices')\n",
    "                        \n",
    "    \n",
    "        \n",
    "    return None\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30377f80-ff35-4605-944d-fc20530e5e3a",
   "metadata": {},
   "source": [
    "Note on probability matrix parsing: \n",
    "- **For one matrix retrieval**: this line of code finds the first matrix instance in the tree (indicated by regex) and gets its value, which is the probability matrix itself. We make a split with `=` first and then index with `[-1]` to ensure we keep the string's end. However, the beginning of the string contains an extra number which is not part of the matrix, so we keep the string from index 3 (`[3:]`). In some cases, an additional white line remains in the beginning of the matrix, but it does not seem to be problematic for posterior loading as a Pandas dataframe, so is preferred to use index 3 instead of index 4.\n",
    "- **For more than one matrix retrieval**: instead, the line of code finds every matrix instance in the tree, according to regex. This search returns a list of matrices, which can be splitted using `\"`. Also, I have checked there is always a replica of the matrix if there is a single one and, appareantly, there are two different matrices at most, but the code is adapted to several. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d7b9ab-0777-41ad-9632-90d4b584593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests OK!\n",
    "def from_prob_to_weight_matrix(prob_m_path, weight_m_path, aa_bg):\n",
    "    \"\"\"\n",
    "    Transforms n probability matrices to weight matrices according to provided aminoacid\n",
    "    background probabilities\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prob_m_path: str\n",
    "                Path to the folder where the probability matrices are located. Each file has to be tab-separated.\n",
    "    weight_m_path: str\n",
    "                Path to the folder where the weight matrices will be located. Each file has to be tab-separated.\n",
    "    aa_bg: numpy.ndarray\n",
    "                Aminoacid background probabilities, sorted the same as columns in the matrices\n",
    "                \n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve probability matrices files names \n",
    "    E3_ligases = os.listdir(prob_m_path)\n",
    "    \n",
    "    # Transform every probability matrix into a weight matrix\n",
    "    \n",
    "    counter = 0                                    # (optional) Monitor number of E3-ligases\n",
    "    \n",
    "    for E3_ligase in E3_ligases:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        prob_m = pd.read_csv(prob_m_path+E3_ligase, sep = \"\\t\")\n",
    "        weight_m = logomaker.transform_matrix(prob_m, from_type = 'probability', to_type = 'weight', background = aa_bg) \n",
    "        # following line commented to avoid file saving (testing run for modifications)\n",
    "        #weight_m.to_csv(weight_m_path+E3_ligase, sep = \"\\t\", header = True, index = False) # index = False to avoid keeping first column (motif positions)\n",
    "                                                                                           # header = True to maintain aa letter names\n",
    "        \n",
    "    \n",
    "    print(f'{counter} transformed probability matrices to weight matrices')\n",
    "    \n",
    "    return None\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3803b52-654e-4bc1-8b90-a0ecad7e9934",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b582cc5-84b1-439f-b468-6735564427b8",
   "metadata": {},
   "source": [
    "### 1. Fetch URL of PPM-containing motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180dd515-ca0f-4d8a-bc2d-380a1b26cbab",
   "metadata": {},
   "source": [
    "First, HTML file is saved from ['Browse E3 ligases'](https://awi.cuhk.edu.cn/~ubinet/browseE3.php) section in UbiNet, opening the navigator's inspector. Find those motifs which contain a PPM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7e73a5-2761-407c-ab0f-4cde4ccf7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motifs links\n",
      "----------------\n",
      "104 retrieved links\n"
     ]
    }
   ],
   "source": [
    "print(\"Motifs links\")\n",
    "print(\"----------------\")\n",
    "regex = \"./data/UbiNet2.0_Motifs_1129/[^NoMotif.html]\"\n",
    "\n",
    "retrieve_motif_links(html_ubinet_path, url_motifs_path, regex,\n",
    "                    save = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db9a61-7071-447b-8d7d-cb339f5b20a5",
   "metadata": {},
   "source": [
    "### 2. Fetch PPMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de702a57-5ae7-4879-b612-017eb0209be5",
   "metadata": {},
   "source": [
    "Only one probability matrix per E3-ligase is retrieved, although in same cases, there is more than one available. The retrieved matrix is supposed to be the one with the highest score, but the code does not have that implementation as it seems the first matrix is always the one with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2841532-1dbb-493e-b315-c9ee5d203687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [04:35,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 retrieved probability matrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "regex = \"letter-probability matrix\"\n",
    "urlbase = \"https://awi.cuhk.edu.cn/~ubinet\"\n",
    "\n",
    "retrieve_prob_matrices(url_motifs_path, prob_m_path, urlbase, regex,\n",
    "                       save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec79c7",
   "metadata": {},
   "source": [
    "For further automatize implementations, we read back all the probability matrices and stored them as tab-delimited dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c05f407-fd5b-4505-8714-45fcbd399ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "E3_ligases = os.listdir(prob_m_path)\n",
    "\n",
    "for E3_ligase in E3_ligases:\n",
    "    \n",
    "    prob_m = pd.read_csv(prob_m_path+E3_ligase, sep = \"  \", header = None, names = aa, engine = 'python')\n",
    "    prob_m.to_csv(prob_m_path+E3_ligase, sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc58a6-2e06-4f69-bfae-077f2770dc56",
   "metadata": {},
   "source": [
    "### 3. Probability matrices transformation to weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d50137-5445-4cfc-a0b4-cec9f53356ef",
   "metadata": {},
   "source": [
    "Transformation performed using `logomaker.transform_matrix` function from logomaker library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e3fea-825b-4a03-b266-e855b4154b13",
   "metadata": {},
   "source": [
    "Requirement: aminoacids background probability, sorted alphabetically by aa to preserve the order of the weight matrices columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7669349-03b3-42f4-9f00-2c9433fc9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 transformed probability matrices to weight matrices\n"
     ]
    }
   ],
   "source": [
    "from_prob_to_weight_matrix(prob_m_path, weight_m_path, aa_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
